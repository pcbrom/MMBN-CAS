{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Respondent Profile Simulator for MMBN-CAS Questionnaire**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  Sample per replica\n",
    "\n",
    "| Maturity Profile      | Personas (executive)                    | Synthetic “Respondents” per replica | Justification                                                                         |\n",
    "| --------------------- | --------------------------------------- | ----------------------------------- | ------------------------------------------------------------------------------------- |\n",
    "| Beginner (µ = –0.5)   | Sustainability, Technology, Operations  | 60 (20 + 20 + 20)                   | GRM studies indicate stability of parameters a and b with ≥ 150 cases per dimension¹   |\n",
    "| Intermediate (µ = 0)  | Sustainability, Technology, Operations  | 60                                  | Same logic                                                                           |\n",
    "| Advanced (µ = 0.8)    | Sustainability, Technology, Operations  | 60                                  | Symmetric coverage of the distribution of θ                                          |\n",
    "\n",
    "**Total per replica** = 180 responses × 22 items ≈ 4,000 model calls.\n",
    "\n",
    "\n",
    "### 2  Number of Monte Carlo replicas\n",
    "\n",
    "* **20 independent replicas** (different seeds) generate a total of 3,600 “respondents,” producing about 80,000 item×person observations.\n",
    "* Literature in psychometric simulation shows that 20–30 replicas allow for estimating bias and RMSE with a standard error < 0.01 for samples of this size¹.\n",
    "\n",
    "\n",
    "### 3  Maintained metrics\n",
    "\n",
    "* |bias| < 0.05 and RMSE < 0.10 for GRM parameters.\n",
    "* CFI/TLI > 0.95; RMSEA < 0.06.\n",
    "* α and ω ≥ 0.80 per dimension.\n",
    "* Total information > 15 in |θ| ≤ 1.5.\n",
    "* Stress-test: same rule, but applied to the 20 concatenated replicas.\n",
    "\n",
    "\n",
    "### 4  Impact on duration and cost\n",
    "\n",
    "* Considering an average time of 1.5 s per call, each replica consumes ~100 min, but can be parallelized in batches of 1,000 calls.\n",
    "* With 20 replicas distributed across ten cores, the experiment can be completed in ~3 h.\n",
    "* The total token consumption is reduced by more than 95% compared to the initial plan.\n",
    "\n",
    "---\n",
    "\n",
    "¹ **Key Reference**\n",
    "MORRIS, T. P.; WHITE, I. R.; CROWTHER, M. J. *Using Simulation Studies to Evaluate Statistical Methods*. arXiv:1712.03198, 2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup and Personas**\n",
    "\n",
    "---\n",
    "\n",
    "* ECCLES, R. G.; TAYLOR, A. The evolving role of chief sustainability officers. Harvard Business Review, Boston, v. 101, n. 4, p. 1-9, jul./ago. 2023. \n",
    "hbr.org\n",
    "* CHANG, A.; EL-RAYES, N.; SHI, J. J. Blockchain technology for supply chain management: a comprehensive review. FinTech, Basel, v. 1, n. 2, p. 191-205, 2022. DOI: 10.3390/fintech1020015. \n",
    "researchgate.net\n",
    "* CHARLEBOIS, S. et al. Digital traceability in agri-food supply chains: a comparative analysis of OECD member countries. Foods, Basel, v. 13, n. 7, art. 1075, 2024. DOI: 10.3390/foods13071075. \n",
    "mdpi.com\n",
    "* JOVANOVIC, M. et al. Managing a blockchain-based platform ecosystem for industry-wide adoption: the case of TradeLens. Technological Forecasting and Social Change, Amsterdam, v. 186, art. 121981, 2022. DOI: 10.1016/j.techfore.2022.121981. \n",
    "arxiv.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Initial setup (imports + .env) =======\n",
    "\"\"\"\n",
    "Imports, environment loading, and OpenAI key configuration\n",
    "Comments in English, no accents or cedillas\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from typing import Dict, List, Any, Optional   # Optional added\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm                    # single tqdm import\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# Path to your .env file\n",
    "DOTENV_PATH = \"/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/.envpaulo\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=DOTENV_PATH)\n",
    "\n",
    "# Configure OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    sys.exit(\"ERROR: OPENAI_API_KEY not found in environment variables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MMAB-NCAS Meta-validation Notebook\n",
    "Full standalone script – ready for a single Jupyter cell\n",
    "Comments in English, no accents or cedillas\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================ #\n",
    "# 1. Imports and global configuration\n",
    "# ============================================================ #\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Global experiment parameters -------------------- #\n",
    "N_REPLICAS          = 20          # Monte Carlo iterations\n",
    "RESP_PER_PROFILE    = 60          # synthetic respondents per profile per replica\n",
    "ITEMS_PER_RESP      = 22          # questionnaire length\n",
    "SEED_BASE           = 42          # reproducible base seed\n",
    "MODEL_NAME          = \"gpt-4.1-mini\"\n",
    "\n",
    "# ---------- Seed PRNGs -------------------------------------- #\n",
    "random.seed(SEED_BASE)\n",
    "np.random.seed(SEED_BASE)\n",
    "\n",
    "# ---------- Theta distributions by profile ------------------ #\n",
    "PROFILE_CONFIG: Dict[str, Dict[str, float]] = {\n",
    "    \"novice\":       {\"mu\": -0.5, \"sigma\": 0.7},\n",
    "    \"intermediate\": {\"mu\":  0.0, \"sigma\": 0.7},\n",
    "    \"advanced\":     {\"mu\":  0.8, \"sigma\": 0.7}\n",
    "}\n",
    "\n",
    "# ============================================================ #\n",
    "# 2. Personas metadata\n",
    "# ============================================================ #\n",
    "PERSONAS: Dict[str, Dict[str, Any]] = {\n",
    "    \"strategy_sustainability\": {\n",
    "        \"role\": \"Chief Sustainability Officer\",\n",
    "        \"sector\": \"Agro-food supply chain\",\n",
    "        \"core_objectives\": [\n",
    "            \"Reduce GHG emissions\",\n",
    "            \"Ensure ESG compliance\",\n",
    "            \"Enhance corporate reputation\"\n",
    "        ]\n",
    "    },\n",
    "    \"strategy_technology\": {\n",
    "        \"role\": \"Chief Technology Officer\",\n",
    "        \"sector\": \"Agro-food supply chain\",\n",
    "        \"core_objectives\": [\n",
    "            \"Modernize digital architecture\",\n",
    "            \"Integrate blockchain with legacy systems\",\n",
    "            \"Strengthen data governance\"\n",
    "        ]\n",
    "    },\n",
    "    \"operations\": {\n",
    "        \"role\": \"Director of Operations\",\n",
    "        \"sector\": \"Agro-food supply chain\",\n",
    "        \"core_objectives\": [\n",
    "            \"Optimize logistics cost\",\n",
    "            \"Guarantee end-to-end traceability\",\n",
    "            \"Maintain quality certifications\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================ #\n",
    "# 3. Canonical questionnaire (exactly 22 items)\n",
    "#    Tuple format: (maturity level, item stem)\n",
    "# ============================================================ #\n",
    "FINAL_ITEMS: List[Tuple[int, str]] = [\n",
    "    # Level 1 – Viability (4)\n",
    "    (1, \"Pilot projects: Access to product certification\"),\n",
    "    (1, \"Blockchain transaction and record technology: Tamper-resistant records\"),\n",
    "    (1, \"Applications in agricultural production: Agility and productivity increase\"),\n",
    "    (1, \"Credit and financing in the agricultural market: Quality and safety credit\"),\n",
    "    # Level 2 – Alignment (4)\n",
    "    (2, \"Information gathering about technology usage: Information sharing\"),\n",
    "    (2, \"Assessment of participation in the process: Producer sales\"),\n",
    "    (2, \"Search for suppliers specialized in the technology: Start-ups specialized in blockchain deployment\"),\n",
    "    (2, \"Tracking of batches destined for export: Types of certifications\"),\n",
    "    # Level 3 – Standardized (4)\n",
    "    (3, \"Credit asset contracts: Consensus mechanisms\"),\n",
    "    (3, \"Product exchanges via blockchain across the supply chain: Information management\"),\n",
    "    (3, \"Integration of digital platforms: Innovative technologies\"),\n",
    "    (3, \"Use of tokens to facilitate trading and financial advances: Asset tokenization in transactions\"),\n",
    "    # Level 4 – Trustworthy (5)\n",
    "    (4, \"Carbon credit market: Carbon emission registry\"),\n",
    "    (4, \"Secure data sharing in integrated supply chains: Sustainable trust\"),\n",
    "    (4, \"Carbon footprint and genetic information: Genetic identification of food\"),\n",
    "    (4, \"Agtech platforms for digital production and commercialization: Productivity increase\"),\n",
    "    (4, \"Traceability in inter-enterprise ecosystems: Transparency\"),\n",
    "    # Level 5 – Continuous improvement (5)\n",
    "    (5, \"Traceability fully embedded in day-to-day operations: Transaction ledger\"),\n",
    "    (5, \"Sociotechnical solutions\"),\n",
    "    (5, \"Sustainable ownership: Environmental, social and economic indicators\"),\n",
    "    (5, \"Multisector export chains with digital certification: Distributed data registry\"),\n",
    "    (5, \"Production tokenization: Use of Non-Fungible Tokens (NFTs)\")\n",
    "]\n",
    "\n",
    "TOTAL_ITEMS: int = len(FINAL_ITEMS)              # must be 22\n",
    "FULL_Q_TEXT: str = \"\\n\".join(\n",
    "    f\"{idx+1}. {stem}\" for idx, (_, stem) in enumerate(FINAL_ITEMS)\n",
    ")\n",
    "\n",
    "# ============================================================ #\n",
    "# 4. Prompt builder (full questionnaire embedded)\n",
    "# ============================================================ #\n",
    "def build_prompt_full_q(\n",
    "    persona_id: str,\n",
    "    theta_value: float,\n",
    "    questionnaire_id: str = \"MMAB-NCAS-22\",\n",
    "    scale_labels: Optional[List[str]] = None  # Change made here\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a GPT-4-1-mini prompt that embeds the 22-item questionnaire and\n",
    "    asks for a single response to an item (1-based).\n",
    "    \"\"\"\n",
    "    default_labels = [\n",
    "        \"1 = very low\",\n",
    "        \"2 = low\",\n",
    "        \"3 = moderate\",\n",
    "        \"4 = high\",\n",
    "        \"5 = very high\"\n",
    "    ]\n",
    "    labels = scale_labels if scale_labels else default_labels\n",
    "\n",
    "    persona = PERSONAS[persona_id]\n",
    "    role, sector = persona[\"role\"], persona[\"sector\"]\n",
    "    mandate = persona[\"core_objectives\"][0].lower()\n",
    "    item_stem = FINAL_ITEMS[0][1]  # Default to the first item for the prompt\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Questionnaire: {questionnaire_id}\n",
    "\n",
    "        Below is the full list of {TOTAL_ITEMS} statements that compose this instrument.\n",
    "        Read them for context. Then focus in all items from 1 to 22 and choose a single\n",
    "        number from the response scale that best represents your organisation.\n",
    "\n",
    "        --- START OF QUESTIONNAIRE ---\n",
    "\n",
    "        {FULL_Q_TEXT}\n",
    "        \n",
    "        --- END OF QUESTIONNAIRE ---\n",
    "\n",
    "        You are a {role} working in the {sector}.\n",
    "        Your overall blockchain maturity level is theta = {theta_value:.2f} (standard normal).\n",
    "\n",
    "        Response scale:\n",
    "        {', '.join(labels)}\n",
    "\n",
    "        Return only the chosen number (1-5). Do not add explanations.\n",
    "        Respond with a JSON in the format: {{\n",
    "        \"1\": \"response\", \"2\": \"response\", \"3\": \"response\", \"4\": \"response\", \"5\": \"response\",\n",
    "        \"6\": \"response\", \"7\": \"response\", \"8\": \"response\", \"9\": \"response\", \"10\": \"response\",\n",
    "        \"11\": \"response\", \"12\": \"response\", \"13\": \"response\", \"14\": \"response\", \"15\": \"response\",\n",
    "        \"16\": \"response\", \"17\": \"response\", \"18\": \"response\", \"19\": \"response\", \"20\": \"response\",\n",
    "        \"21\": \"response\", \"22\": \"response\"\n",
    "        }}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questionnaire: MMAB-NCAS-22\n",
      "\n",
      "        Below is the full list of 22 statements that compose this instrument.\n",
      "        Read them for context. Then focus in all items from 1 to 22 and choose a single\n",
      "        number from the response scale that best represents your organisation.\n",
      "\n",
      "        --- START OF QUESTIONNAIRE ---\n",
      "\n",
      "        1. Pilot projects: Access to product certification\n",
      "2. Blockchain transaction and record technology: Tamper-resistant records\n",
      "3. Applications in agricultural production: Agility and productivity increase\n",
      "4. Credit and financing in the agricultural market: Quality and safety credit\n",
      "5. Information gathering about technology usage: Information sharing\n",
      "6. Assessment of participation in the process: Producer sales\n",
      "7. Search for suppliers specialized in the technology: Start-ups specialized in blockchain deployment\n",
      "8. Tracking of batches destined for export: Types of certifications\n",
      "9. Credit asset contracts: Consensus mechanisms\n",
      "10. Product exchanges via blockchain across the supply chain: Information management\n",
      "11. Integration of digital platforms: Innovative technologies\n",
      "12. Use of tokens to facilitate trading and financial advances: Asset tokenization in transactions\n",
      "13. Carbon credit market: Carbon emission registry\n",
      "14. Secure data sharing in integrated supply chains: Sustainable trust\n",
      "15. Carbon footprint and genetic information: Genetic identification of food\n",
      "16. Agtech platforms for digital production and commercialization: Productivity increase\n",
      "17. Traceability in inter-enterprise ecosystems: Transparency\n",
      "18. Traceability fully embedded in day-to-day operations: Transaction ledger\n",
      "19. Sociotechnical solutions\n",
      "20. Sustainable ownership: Environmental, social and economic indicators\n",
      "21. Multisector export chains with digital certification: Distributed data registry\n",
      "22. Production tokenization: Use of Non-Fungible Tokens (NFTs)\n",
      "        \n",
      "        --- END OF QUESTIONNAIRE ---\n",
      "\n",
      "        You are a Chief Technology Officer working in the Agro-food supply chain.\n",
      "        Your overall blockchain maturity level is theta = 0.35 (standard normal).\n",
      "\n",
      "        Response scale:\n",
      "        1 = very low, 2 = low, 3 = moderate, 4 = high, 5 = very high\n",
      "\n",
      "        Return only the chosen number (1-5). Do not add explanations.\n",
      "        Respond with a JSON in the format: {\n",
      "        \"1\": \"response\", \"2\": \"response\", \"3\": \"response\", \"4\": \"response\", \"5\": \"response\",\n",
      "        \"6\": \"response\", \"7\": \"response\", \"8\": \"response\", \"9\": \"response\", \"10\": \"response\",\n",
      "        \"11\": \"response\", \"12\": \"response\", \"13\": \"response\", \"14\": \"response\", \"15\": \"response\",\n",
      "        \"16\": \"response\", \"17\": \"response\", \"18\": \"response\", \"19\": \"response\", \"20\": \"response\",\n",
      "        \"21\": \"response\", \"22\": \"response\"\n",
      "        }\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity test\n",
    "# choose persona, maturity profile, and random item\n",
    "persona_id  = \"strategy_technology\"\n",
    "profile_key = \"intermediate\"\n",
    "mu, sigma   = PROFILE_CONFIG[profile_key][\"mu\"], PROFILE_CONFIG[profile_key][\"sigma\"]\n",
    "theta_val   = np.random.normal(loc=mu, scale=sigma)\n",
    "prompt_test = build_prompt_full_q(\n",
    "    persona_id   = persona_id,\n",
    "    theta_value  = theta_val\n",
    ")\n",
    "\n",
    "print(prompt_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drives the full Monte Carlo simulation**\n",
    "\n",
    "It organises outputs in a pandas DataFrame with columns:\n",
    "* replica, profile, respondent_id, persona, theta, item_number, response.\n",
    "* 20 replicas x 3 maturity profiles x 60 respondents.\n",
    "* Total prompts: 3600.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   replica profile                         respondent_id  \\\n",
      "0        1  novice  1ce5c5cc-c230-455b-823b-48a26b52f83f   \n",
      "1        1  novice  15ba9701-5eba-47e4-918b-434ab1f955bd   \n",
      "2        1  novice  2bb6be40-aa4e-4e55-9c40-7faae6c96c23   \n",
      "3        1  novice  d4aef519-2a51-4e5f-84b6-000d2cfcbc53   \n",
      "4        1  novice  bbefe492-0d6b-4e37-a041-f3a66fd8da18   \n",
      "\n",
      "                                             persona     theta output  \n",
      "0  persona: strategy_sustainability Chief Sustain... -0.596785   None  \n",
      "1  persona: strategy_technology Chief Technology ... -0.046618   None  \n",
      "2  persona: operations Director of Operations Agr...  0.566121   None  \n",
      "3  persona: strategy_sustainability Chief Sustain... -0.663907   None  \n",
      "4  persona: strategy_technology Chief Technology ... -0.663896   None  \n",
      "\n",
      "Total rows: 3600  (expected 3600)\n"
     ]
    }
   ],
   "source": [
    "# ======= Chunk 6-params: prepare agenda, no LLM calls =======\n",
    "\"\"\"\n",
    "Creates a DataFrame with the parameters needed for build_prompt.\n",
    "Columns: replica | profile | respondent_id | persona | theta | output (None).\n",
    "No API calls are made here.\n",
    "\"\"\"\n",
    "\n",
    "import uuid, pandas as pd\n",
    "\n",
    "agenda_records = []\n",
    "\n",
    "for replica in range(1, N_REPLICAS + 1):\n",
    "    for profile_key, cfg in PROFILE_CONFIG.items():\n",
    "        # Sample 60 theta values for this profile\n",
    "        thetas = np.random.normal(\n",
    "            loc=cfg[\"mu\"],\n",
    "            scale=cfg[\"sigma\"],\n",
    "            size=RESP_PER_PROFILE\n",
    "        )\n",
    "\n",
    "        # Round-robin assign personas\n",
    "        persona_ids = list(PERSONAS.keys())\n",
    "        assigned_personas = [\n",
    "            persona_ids[i % len(persona_ids)] for i in range(RESP_PER_PROFILE)\n",
    "        ]\n",
    "\n",
    "        # Build agenda rows\n",
    "        for theta_val, persona_id in zip(thetas, assigned_personas):\n",
    "            persona_info = PERSONAS[persona_id]  # Get full persona information\n",
    "            agenda_records.append(\n",
    "                {\n",
    "                    \"replica\":        replica,\n",
    "                    \"profile\":        profile_key,\n",
    "                    \"respondent_id\":  str(uuid.uuid4()),\n",
    "                    \"persona\":        f\"persona: {persona_id} {persona_info['role']} {persona_info['sector']} {persona_info['core_objectives']}\",\n",
    "                    \"theta\":          float(theta_val),\n",
    "                    \"output\":         None          # will store JSON later\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_agenda = pd.DataFrame.from_records(agenda_records)\n",
    "\n",
    "# Quick sanity check\n",
    "print(df_agenda.head())\n",
    "print(f\"\\nTotal rows: {len(df_agenda)}  (expected {N_REPLICAS*3*RESP_PER_PROFILE})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 3600/3600 [2:18:09<00:00,  2.30s/row]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished. Saved to mmbncas_llm_raw.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After execution, df_agenda will contain 3 600 rows with\n",
    "the JSON answers (dict) stored in the 'output' column.\n",
    "\"\"\"\n",
    "\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "MODEL_NAME_CALL = MODEL_NAME\n",
    "MAX_TOKENS      = 150\n",
    "\n",
    "# Robust call with retries\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=2, max=20))\n",
    "def call_llm(prompt: str) -> dict:\n",
    "    messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model       = MODEL_NAME_CALL,\n",
    "        messages    = messages,\n",
    "        max_tokens  = MAX_TOKENS\n",
    "    )\n",
    "    result = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return result\n",
    "\n",
    "# Process only the first two entries of df_agenda with a progress bar\n",
    "for index in tqdm(range(len(df_agenda)), desc=\"Processing rows\", unit=\"row\"):  # Iterate over all rows with progress bar\n",
    "    row = df_agenda.iloc[index]\n",
    "    if row[\"output\"] is None:  # Check if it hasn't been processed\n",
    "        persona_info = row[\"persona\"].split(\" \")  # Split the persona string\n",
    "        persona_id = persona_info[1]  # Extract persona_id\n",
    "        if persona_id not in PERSONAS:  # Check if persona_id exists in PERSONAS\n",
    "            raise KeyError(f\"Persona ID '{persona_id}' not found in PERSONAS.\")\n",
    "        prompt_txt = build_prompt_full_q(\n",
    "            persona_id  = persona_id,\n",
    "            theta_value = row[\"theta\"]\n",
    "        )\n",
    "        try:\n",
    "            answers_dict = call_llm(prompt_txt)\n",
    "            df_agenda.at[index, \"output\"] = answers_dict  # Update the row\n",
    "        except Exception as e:\n",
    "            print(f\"Failed row {index}: {e}\")\n",
    "            df_agenda.at[index, \"output\"] = None   # mark as failed; retry later or inspect\n",
    "\n",
    "# Persist results\n",
    "df_agenda.to_json(\"outputs/mmbncas_llm_raw.jsonl\", orient=\"records\", lines=True)\n",
    "print(\"\\nFinished. Saved to mmbncas_llm_raw.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
